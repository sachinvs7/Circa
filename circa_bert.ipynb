{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-09T14:52:20.167523Z",
     "iopub.status.busy": "2023-10-09T14:52:20.167182Z",
     "iopub.status.idle": "2023-10-09T14:52:28.832521Z",
     "shell.execute_reply": "2023-10-09T14:52:28.831358Z",
     "shell.execute_reply.started": "2023-10-09T14:52:20.167494Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpu = gpus[0]\n",
    "\n",
    "tf.config.experimental.set_memory_growth(gpu, True)\n",
    "import transformers\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:52:31.085124Z",
     "iopub.status.busy": "2023-10-09T14:52:31.084574Z",
     "iopub.status.idle": "2023-10-09T14:52:31.090902Z",
     "shell.execute_reply": "2023-10-09T14:52:31.089048Z",
     "shell.execute_reply.started": "2023-10-09T14:52:31.085095Z"
    }
   },
   "outputs": [],
   "source": [
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:52:33.199315Z",
     "iopub.status.busy": "2023-10-09T14:52:33.198924Z",
     "iopub.status.idle": "2023-10-09T14:52:33.519441Z",
     "shell.execute_reply": "2023-10-09T14:52:33.518443Z",
     "shell.execute_reply.started": "2023-10-09T14:52:33.199282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question-X</th>\n",
       "      <th>canquestion-X</th>\n",
       "      <th>answer-Y</th>\n",
       "      <th>judgements</th>\n",
       "      <th>goldstandard1</th>\n",
       "      <th>goldstandard2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Y has just travelled from a different city to ...</td>\n",
       "      <td>Are you employed?</td>\n",
       "      <td>I am employed .</td>\n",
       "      <td>I'm a veterinary technician.</td>\n",
       "      <td>Yes#Yes#Yes#Yes#Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>X wants to know about Y's food preferences.</td>\n",
       "      <td>Are you a fan of Korean food?</td>\n",
       "      <td>I am a fan of Korean food .</td>\n",
       "      <td>I wouldn't say so</td>\n",
       "      <td>Probably no#No#No#No#Probably yes / sometimes yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Y has just told X that he/she is thinking of b...</td>\n",
       "      <td>Are you bringing any pets into the flat?</td>\n",
       "      <td>I am bringing pets into the flat .</td>\n",
       "      <td>I do not own any pets</td>\n",
       "      <td>No#No#No#No#No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>X wants to know what activities Y likes to do ...</td>\n",
       "      <td>Would you like to get some fresh air in your f...</td>\n",
       "      <td>I would like to get fresh air in my free time .</td>\n",
       "      <td>I am desperate to get out of the city.</td>\n",
       "      <td>Yes#Yes, subject to some conditions#Probably y...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>X and Y are childhood neighbours who unexpecte...</td>\n",
       "      <td>Is your family still living in the neighborhood?</td>\n",
       "      <td>My family is living in the neighborhood .</td>\n",
       "      <td>My parents are snowbirds now.</td>\n",
       "      <td>No#In the middle, neither yes nor no#Probably ...</td>\n",
       "      <td>In the middle, neither yes nor no</td>\n",
       "      <td>In the middle, neither yes nor no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            context  \\\n",
       "0   0  Y has just travelled from a different city to ...   \n",
       "1   1        X wants to know about Y's food preferences.   \n",
       "2   2  Y has just told X that he/she is thinking of b...   \n",
       "3   3  X wants to know what activities Y likes to do ...   \n",
       "4   4  X and Y are childhood neighbours who unexpecte...   \n",
       "\n",
       "                                          question-X  \\\n",
       "0                                  Are you employed?   \n",
       "1                      Are you a fan of Korean food?   \n",
       "2           Are you bringing any pets into the flat?   \n",
       "3  Would you like to get some fresh air in your f...   \n",
       "4   Is your family still living in the neighborhood?   \n",
       "\n",
       "                                     canquestion-X  \\\n",
       "0                                  I am employed .   \n",
       "1                      I am a fan of Korean food .   \n",
       "2               I am bringing pets into the flat .   \n",
       "3  I would like to get fresh air in my free time .   \n",
       "4        My family is living in the neighborhood .   \n",
       "\n",
       "                                 answer-Y  \\\n",
       "0            I'm a veterinary technician.   \n",
       "1                       I wouldn't say so   \n",
       "2                   I do not own any pets   \n",
       "3  I am desperate to get out of the city.   \n",
       "4           My parents are snowbirds now.   \n",
       "\n",
       "                                          judgements  \\\n",
       "0                                Yes#Yes#Yes#Yes#Yes   \n",
       "1  Probably no#No#No#No#Probably yes / sometimes yes   \n",
       "2                                     No#No#No#No#No   \n",
       "3  Yes#Yes, subject to some conditions#Probably y...   \n",
       "4  No#In the middle, neither yes nor no#Probably ...   \n",
       "\n",
       "                       goldstandard1                      goldstandard2  \n",
       "0                                Yes                                Yes  \n",
       "1                                 No                                 No  \n",
       "2                                 No                                 No  \n",
       "3                                Yes                                Yes  \n",
       "4  In the middle, neither yes nor no  In the middle, neither yes nor no  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('../input/circa-dataset/circa-data.tsv',sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:52:36.937502Z",
     "iopub.status.busy": "2023-10-09T14:52:36.937143Z",
     "iopub.status.idle": "2023-10-09T14:52:36.954340Z",
     "shell.execute_reply": "2023-10-09T14:52:36.953439Z",
     "shell.execute_reply.started": "2023-10-09T14:52:36.937473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34268, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "context\n",
       "Y has just told X that he/she is thinking of buying a flat in New York.             3500\n",
       "Y has just travelled from a different city to meet X.                               3487\n",
       "X wants to know about Y's music preferences.                                        3483\n",
       "Y has just told X that he/she is considering switching his/her job.                 3479\n",
       "X wants to know what activities Y likes to do during weekends.                      3465\n",
       "X and Y are colleagues who are leaving work on a Friday at the same time.           3452\n",
       "X wants to know what sorts of books Y likes to read.                                3445\n",
       "X and Y are childhood neighbours who unexpectedly run into each other at a cafe.    3391\n",
       "Y has just moved into a neighbourhood and meets his/her new neighbour X.            3356\n",
       "X wants to know about Y's food preferences.                                         3210\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data['context'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:52:40.886831Z",
     "iopub.status.busy": "2023-10-09T14:52:40.886509Z",
     "iopub.status.idle": "2023-10-09T14:52:40.896684Z",
     "shell.execute_reply": "2023-10-09T14:52:40.895111Z",
     "shell.execute_reply.started": "2023-10-09T14:52:40.886805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "goldstandard1\n",
       "Yes                                              14504\n",
       "No                                               10829\n",
       "Yes, subject to some conditions                   2583\n",
       "Probably yes / sometimes yes                      1244\n",
       "Probably no                                       1160\n",
       "In the middle, neither yes nor no                  638\n",
       "Other                                              504\n",
       "I am not sure how X will interpret Y’s answer       63\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['goldstandard1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:52:43.274812Z",
     "iopub.status.busy": "2023-10-09T14:52:43.273764Z",
     "iopub.status.idle": "2023-10-09T14:52:43.284877Z",
     "shell.execute_reply": "2023-10-09T14:52:43.283812Z",
     "shell.execute_reply.started": "2023-10-09T14:52:43.274774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "goldstandard2\n",
       "Yes                                  16628\n",
       "No                                   12833\n",
       "Yes, subject to some conditions       2583\n",
       "In the middle, neither yes nor no      949\n",
       "Other                                  504\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['goldstandard2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:53:00.995252Z",
     "iopub.status.busy": "2023-10-09T14:53:00.994918Z",
     "iopub.status.idle": "2023-10-09T14:53:01.013091Z",
     "shell.execute_reply": "2023-10-09T14:53:01.012030Z",
     "shell.execute_reply.started": "2023-10-09T14:53:00.995226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                  0\n",
      "context             0\n",
      "question-X          0\n",
      "canquestion-X      10\n",
      "answer-Y            0\n",
      "judgements          0\n",
      "goldstandard1    2743\n",
      "goldstandard2     771\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#data = data.dropna()\n",
    "print(data.isnull().sum())\n",
    "# data['goldstandard1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:53:03.583518Z",
     "iopub.status.busy": "2023-10-09T14:53:03.583170Z",
     "iopub.status.idle": "2023-10-09T14:53:03.610744Z",
     "shell.execute_reply": "2023-10-09T14:53:03.609590Z",
     "shell.execute_reply.started": "2023-10-09T14:53:03.583491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "goldstandard2\n",
       "Yes                                  15745\n",
       "No                                   11985\n",
       "Yes, subject to some conditions       2580\n",
       "In the middle, neither yes nor no      701\n",
       "Other                                  504\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data['goldstandard2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-23T22:42:24.931908Z",
     "iopub.status.busy": "2022-09-23T22:42:24.931205Z",
     "iopub.status.idle": "2022-09-23T22:42:24.938998Z",
     "shell.execute_reply": "2022-09-23T22:42:24.935962Z",
     "shell.execute_reply.started": "2022-09-23T22:42:24.931872Z"
    }
   },
   "outputs": [],
   "source": [
    "# data['label'] = data['goldstandard1'].copy()\n",
    "\n",
    "# data['label'] = data['label'].map({'Yes': 0, 'No': 1, 'Yes, subject to some conditions': 2,\n",
    "#                                   'Probably yes / sometimes yes': 3, 'Probably no': 4,\n",
    "#                                   'In the middle, neither yes nor no': 5, 'Other': 6,\n",
    "#                                   'I am not sure how X will interpret Y’s answer': 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:53:08.573432Z",
     "iopub.status.busy": "2023-10-09T14:53:08.572937Z",
     "iopub.status.idle": "2023-10-09T14:53:08.586251Z",
     "shell.execute_reply": "2023-10-09T14:53:08.585321Z",
     "shell.execute_reply.started": "2023-10-09T14:53:08.573368Z"
    }
   },
   "outputs": [],
   "source": [
    "data['label_2'] = data['goldstandard2'].copy()\n",
    "\n",
    "data['label_2'] = data['label_2'].map({'Yes': 0, 'No': 1, 'Yes, subject to some conditions': 2,\n",
    "                                  'In the middle, neither yes nor no': 3, 'Other': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:53:10.757042Z",
     "iopub.status.busy": "2023-10-09T14:53:10.756719Z",
     "iopub.status.idle": "2023-10-09T14:53:10.766811Z",
     "shell.execute_reply": "2023-10-09T14:53:10.765890Z",
     "shell.execute_reply.started": "2023-10-09T14:53:10.757016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_2\n",
       "0    15745\n",
       "1    11985\n",
       "2     2580\n",
       "3      701\n",
       "4      504\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:53:13.055191Z",
     "iopub.status.busy": "2023-10-09T14:53:13.054847Z",
     "iopub.status.idle": "2023-10-09T14:53:13.060143Z",
     "shell.execute_reply": "2023-10-09T14:53:13.058771Z",
     "shell.execute_reply.started": "2023-10-09T14:53:13.055164Z"
    }
   },
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:53:15.935542Z",
     "iopub.status.busy": "2023-10-09T14:53:15.935195Z",
     "iopub.status.idle": "2023-10-09T14:53:16.261317Z",
     "shell.execute_reply": "2023-10-09T14:53:16.260453Z",
     "shell.execute_reply.started": "2023-10-09T14:53:15.935514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.602189433603046\n",
      "5.699095668729177\n"
     ]
    }
   ],
   "source": [
    "#Length of avg question\n",
    "q = []\n",
    "for x in range(data.shape[0]):\n",
    "    q.append(len(data['question-X'][x].split()))\n",
    "    \n",
    "#Length of avg answer\n",
    "a = []\n",
    "for x in range(data.shape[0]):\n",
    "    a.append(len(data['answer-Y'][x].split()))\n",
    "    \n",
    "print(statistics.mean(q))\n",
    "print(statistics.mean(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:53:18.919589Z",
     "iopub.status.busy": "2023-10-09T14:53:18.919247Z",
     "iopub.status.idle": "2023-10-09T14:53:18.953171Z",
     "shell.execute_reply": "2023-10-09T14:53:18.952130Z",
     "shell.execute_reply.started": "2023-10-09T14:53:18.919560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25212, 9) (6303, 9)\n",
      "(21430, 2)\n",
      "(3782, 2)\n",
      "(21430, 5)\n",
      "(3782, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train , test = train_test_split(data, test_size = 0.20)\n",
    "\n",
    "# train['sep_token'] = '[SEP]'\n",
    "# train['cls_token'] = '[CLS]'\n",
    "# train['text'] = train['cls_token'] + \\\n",
    "#                     train['context'] + train['sep_token']+ train['question-X'] + \\\n",
    "#                     train['sep_token'] + train['answer-Y'] + \\\n",
    "#                 train['sep_token']\n",
    "\n",
    "\n",
    "X = train[['question-X', 'answer-Y']]\n",
    "y = tf.keras.utils.to_categorical(train.label_2, num_classes=5)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.15)\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:53:21.416094Z",
     "iopub.status.busy": "2023-10-09T14:53:21.415770Z",
     "iopub.status.idle": "2023-10-09T14:53:21.420824Z",
     "shell.execute_reply": "2023-10-09T14:53:21.419450Z",
     "shell.execute_reply.started": "2023-10-09T14:53:21.416068Z"
    }
   },
   "outputs": [],
   "source": [
    "max_length = None\n",
    "epochs = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T15:57:44.157573Z",
     "iopub.status.busy": "2023-10-09T15:57:44.157221Z",
     "iopub.status.idle": "2023-10-09T15:57:44.166304Z",
     "shell.execute_reply": "2023-10-09T15:57:44.165339Z",
     "shell.execute_reply.started": "2023-10-09T15:57:44.157543Z"
    }
   },
   "outputs": [],
   "source": [
    "class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sentence_pairs,\n",
    "        labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        include_targets=True,\n",
    "    ):\n",
    "        self.sentence_pairs = sentence_pairs\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.include_targets = include_targets\n",
    "        # Load BERT tokenizer to encode the text\n",
    "        # base-base-uncased pretrained model\n",
    "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n",
    "            \"bert-base-uncased\", do_lower_case=True\n",
    "        )\n",
    "        self.indexes = np.arange(len(self.sentence_pairs))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch\n",
    "        return len(self.sentence_pairs) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieves the batch of index\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        sentence_pairs = self.sentence_pairs[indexes]\n",
    "\n",
    "        # With BERT tokenizer's batch_encode_plus, a batch of both the sentences are\n",
    "        # encoded together and separated by [SEP] token\n",
    "        encoded = self.tokenizer.batch_encode_plus(\n",
    "            sentence_pairs.tolist(),\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            pad_to_max_length=True,\n",
    "            return_tensors=\"tf\",\n",
    "        )\n",
    "\n",
    "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
    "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
    "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
    "\n",
    "        # Set to True if data generator is used for training/validation\n",
    "        if self.include_targets:\n",
    "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
    "            return [input_ids, attention_masks, token_type_ids], labels\n",
    "        else:\n",
    "            return [input_ids, attention_masks, token_type_ids]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle indices after each epoch, if shuffle is set to True\n",
    "        if self.shuffle:\n",
    "            np.random.RandomState(42).shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:53:57.351752Z",
     "iopub.status.busy": "2023-10-09T14:53:57.351430Z",
     "iopub.status.idle": "2023-10-09T14:54:16.269559Z",
     "shell.execute_reply": "2023-10-09T14:54:16.268620Z",
     "shell.execute_reply.started": "2023-10-09T14:53:57.351727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb410348a124559ae1b6b53615a3fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555ea3f7f56546059103d1181263f4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_ids = tf.keras.layers.Input(\n",
    "    shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n",
    ")\n",
    "attention_masks = tf.keras.layers.Input(\n",
    "    shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n",
    ")\n",
    "token_type_ids = tf.keras.layers.Input(\n",
    "    shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n",
    ")\n",
    "# Loading pretrained BERT model\n",
    "bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "# Freeze the BERT model to reuse the pretrained features without modifying them\n",
    "bert_model.trainable = False\n",
    "\n",
    "bert_output = bert_model(\n",
    "    input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",
    ")\n",
    "sequence_output = bert_output.last_hidden_state\n",
    "pooled_output = bert_output.pooler_output\n",
    "#dropout = tf.keras.layers.Dropout(0.1)(pooled_output)\n",
    "clf_output = sequence_output[:, 0, :]\n",
    "output = tf.keras.layers.Dense(5, activation=\"softmax\")(clf_output)\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"acc\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:54:32.040911Z",
     "iopub.status.busy": "2023-10-09T14:54:32.040059Z",
     "iopub.status.idle": "2023-10-09T14:54:32.085406Z",
     "shell.execute_reply": "2023-10-09T14:54:32.084696Z",
     "shell.execute_reply.started": "2023-10-09T14:54:32.040880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " attention_masks (InputLayer)   [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n",
      "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
      "                                n_state=(None, None                                               \n",
      "                                , 768),                                                           \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5)            3845        ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,486,085\n",
      "Trainable params: 3,845\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:55:00.462576Z",
     "iopub.status.busy": "2023-10-09T14:55:00.462199Z",
     "iopub.status.idle": "2023-10-09T14:55:01.311394Z",
     "shell.execute_reply": "2023-10-09T14:55:01.310500Z",
     "shell.execute_reply.started": "2023-10-09T14:55:00.462546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889ea142c63b4ce18238c386014d2a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1636e4a68c04de1b03b208f6927c612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = BertSemanticDataGenerator(\n",
    "    X_train[['question-X', 'answer-Y']].values.astype(\"str\"),\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "valid_data = BertSemanticDataGenerator(\n",
    "    X_val[['question-X', 'answer-Y']].values.astype(\"str\"),\n",
    "    y_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:55:04.515499Z",
     "iopub.status.busy": "2023-10-09T14:55:04.515150Z",
     "iopub.status.idle": "2023-10-09T14:55:04.520963Z",
     "shell.execute_reply": "2023-10-09T14:55:04.519831Z",
     "shell.execute_reply.started": "2023-10-09T14:55:04.515472Z"
    }
   },
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint('circa_qa_bert_trial.h5',\n",
    "                                                monitor='val_loss',\n",
    "                                                mode='min',\n",
    "                                                save_best_only=True,\n",
    "                                                save_weights_only=True,\n",
    "                                                verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                          mode='min',\n",
    "                                                          patience=3,\n",
    "                                                          verbose=1)\n",
    "\n",
    "callbacks_list = [early_stopping, cp_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:55:11.023422Z",
     "iopub.status.busy": "2023-10-09T14:55:11.023044Z",
     "iopub.status.idle": "2023-10-09T14:55:11.028900Z",
     "shell.execute_reply": "2023-10-09T14:55:11.028018Z",
     "shell.execute_reply.started": "2023-10-09T14:55:11.023374Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test = tf.keras.utils.to_categorical(test.label_2, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:55:16.259117Z",
     "iopub.status.busy": "2023-10-09T14:55:16.258780Z",
     "iopub.status.idle": "2023-10-09T14:55:16.389730Z",
     "shell.execute_reply": "2023-10-09T14:55:16.388778Z",
     "shell.execute_reply.started": "2023-10-09T14:55:16.259090Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = BertSemanticDataGenerator(\n",
    "    test[[\"question-X\", \"answer-Y\"]].values.astype(\"str\"),\n",
    "    y_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:55:19.273301Z",
     "iopub.status.busy": "2023-10-09T14:55:19.272976Z",
     "iopub.status.idle": "2023-10-09T14:55:19.285362Z",
     "shell.execute_reply": "2023-10-09T14:55:19.284346Z",
     "shell.execute_reply.started": "2023-10-09T14:55:19.273275Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>context</th>\n",
       "      <th>question-X</th>\n",
       "      <th>canquestion-X</th>\n",
       "      <th>answer-Y</th>\n",
       "      <th>judgements</th>\n",
       "      <th>goldstandard1</th>\n",
       "      <th>goldstandard2</th>\n",
       "      <th>label_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16622</th>\n",
       "      <td>18238</td>\n",
       "      <td>Y has just told X that he/she is thinking of b...</td>\n",
       "      <td>Are you moving to New York?</td>\n",
       "      <td>I am moving to New York .</td>\n",
       "      <td>I'll be living on 14th Street.</td>\n",
       "      <td>Yes#Yes#Yes#Yes#Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>1503</td>\n",
       "      <td>X wants to know about Y's music preferences.</td>\n",
       "      <td>Do you like to attend concerts?</td>\n",
       "      <td>I like to attend concerts .</td>\n",
       "      <td>I go to one a week</td>\n",
       "      <td>Yes#Yes#Yes#Probably yes / sometimes yes#Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29744</th>\n",
       "      <td>32326</td>\n",
       "      <td>Y has just moved into a neighbourhood and meet...</td>\n",
       "      <td>Do you play any sports?</td>\n",
       "      <td>I play sports .</td>\n",
       "      <td>Soccer, football, and tennis.</td>\n",
       "      <td>Yes#Yes#Yes#Yes#Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>4702</td>\n",
       "      <td>X and Y are colleagues who are leaving work on...</td>\n",
       "      <td>Is today pay day?</td>\n",
       "      <td>Today is pay day .</td>\n",
       "      <td>I hope so</td>\n",
       "      <td>In the middle, neither yes nor no#Probably yes...</td>\n",
       "      <td>In the middle, neither yes nor no</td>\n",
       "      <td>In the middle, neither yes nor no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29424</th>\n",
       "      <td>31972</td>\n",
       "      <td>X wants to know about Y's food preferences.</td>\n",
       "      <td>Would you prefer a vegetarian restaurant?</td>\n",
       "      <td>I would prefer a vegetarian restaurant .</td>\n",
       "      <td>I would prefer a place where I can order steak.</td>\n",
       "      <td>No#Probably no#No#No#No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            context  \\\n",
       "16622  18238  Y has just told X that he/she is thinking of b...   \n",
       "1349    1503       X wants to know about Y's music preferences.   \n",
       "29744  32326  Y has just moved into a neighbourhood and meet...   \n",
       "4261    4702  X and Y are colleagues who are leaving work on...   \n",
       "29424  31972        X wants to know about Y's food preferences.   \n",
       "\n",
       "                                      question-X  \\\n",
       "16622                Are you moving to New York?   \n",
       "1349             Do you like to attend concerts?   \n",
       "29744                    Do you play any sports?   \n",
       "4261                           Is today pay day?   \n",
       "29424  Would you prefer a vegetarian restaurant?   \n",
       "\n",
       "                                  canquestion-X  \\\n",
       "16622                 I am moving to New York .   \n",
       "1349                I like to attend concerts .   \n",
       "29744                           I play sports .   \n",
       "4261                         Today is pay day .   \n",
       "29424  I would prefer a vegetarian restaurant .   \n",
       "\n",
       "                                              answer-Y  \\\n",
       "16622                   I'll be living on 14th Street.   \n",
       "1349                                I go to one a week   \n",
       "29744                    Soccer, football, and tennis.   \n",
       "4261                                         I hope so   \n",
       "29424  I would prefer a place where I can order steak.   \n",
       "\n",
       "                                              judgements  \\\n",
       "16622                                Yes#Yes#Yes#Yes#Yes   \n",
       "1349        Yes#Yes#Yes#Probably yes / sometimes yes#Yes   \n",
       "29744                                Yes#Yes#Yes#Yes#Yes   \n",
       "4261   In the middle, neither yes nor no#Probably yes...   \n",
       "29424                            No#Probably no#No#No#No   \n",
       "\n",
       "                           goldstandard1                      goldstandard2  \\\n",
       "16622                                Yes                                Yes   \n",
       "1349                                 Yes                                Yes   \n",
       "29744                                Yes                                Yes   \n",
       "4261   In the middle, neither yes nor no  In the middle, neither yes nor no   \n",
       "29424                                 No                                 No   \n",
       "\n",
       "       label_2  \n",
       "16622        0  \n",
       "1349         0  \n",
       "29744        0  \n",
       "4261         3  \n",
       "29424        1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T14:55:23.456709Z",
     "iopub.status.busy": "2023-10-09T14:55:23.456341Z",
     "iopub.status.idle": "2023-10-09T15:14:04.818710Z",
     "shell.execute_reply": "2023-10-09T15:14:04.817844Z",
     "shell.execute_reply.started": "2023-10-09T14:55:23.456683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/669 [==============================] - ETA: 0s - loss: 0.8086 - acc: 0.6685\n",
      "Epoch 1: val_loss improved from inf to 0.68664, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 67s 81ms/step - loss: 0.8086 - acc: 0.6685 - val_loss: 0.6866 - val_acc: 0.7402\n",
      "Epoch 2/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6908 - acc: 0.7363\n",
      "Epoch 2: val_loss improved from 0.68664 to 0.64145, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 51s 77ms/step - loss: 0.6908 - acc: 0.7363 - val_loss: 0.6415 - val_acc: 0.7587\n",
      "Epoch 3/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6657 - acc: 0.7410\n",
      "Epoch 3: val_loss improved from 0.64145 to 0.62393, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 51s 76ms/step - loss: 0.6657 - acc: 0.7410 - val_loss: 0.6239 - val_acc: 0.7741\n",
      "Epoch 4/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6489 - acc: 0.7456\n",
      "Epoch 4: val_loss did not improve from 0.62393\n",
      "669/669 [==============================] - 50s 75ms/step - loss: 0.6489 - acc: 0.7456 - val_loss: 0.6318 - val_acc: 0.7609\n",
      "Epoch 5/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6384 - acc: 0.7512\n",
      "Epoch 5: val_loss improved from 0.62393 to 0.60449, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 51s 77ms/step - loss: 0.6384 - acc: 0.7512 - val_loss: 0.6045 - val_acc: 0.7767\n",
      "Epoch 6/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6284 - acc: 0.7538\n",
      "Epoch 6: val_loss improved from 0.60449 to 0.58968, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 52s 77ms/step - loss: 0.6284 - acc: 0.7538 - val_loss: 0.5897 - val_acc: 0.7781\n",
      "Epoch 7/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6196 - acc: 0.7552\n",
      "Epoch 7: val_loss improved from 0.58968 to 0.58735, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 51s 77ms/step - loss: 0.6196 - acc: 0.7552 - val_loss: 0.5874 - val_acc: 0.7738\n",
      "Epoch 8/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6201 - acc: 0.7564\n",
      "Epoch 8: val_loss did not improve from 0.58735\n",
      "669/669 [==============================] - 49s 74ms/step - loss: 0.6201 - acc: 0.7564 - val_loss: 0.5976 - val_acc: 0.7669\n",
      "Epoch 9/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6148 - acc: 0.7546\n",
      "Epoch 9: val_loss did not improve from 0.58735\n",
      "669/669 [==============================] - 50s 75ms/step - loss: 0.6148 - acc: 0.7546 - val_loss: 0.5965 - val_acc: 0.7736\n",
      "Epoch 10/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6162 - acc: 0.7539\n",
      "Epoch 10: val_loss improved from 0.58735 to 0.58693, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 52s 77ms/step - loss: 0.6162 - acc: 0.7539 - val_loss: 0.5869 - val_acc: 0.7746\n",
      "Epoch 11/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6156 - acc: 0.7582\n",
      "Epoch 11: val_loss improved from 0.58693 to 0.57561, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 51s 77ms/step - loss: 0.6156 - acc: 0.7582 - val_loss: 0.5756 - val_acc: 0.7836\n",
      "Epoch 12/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6095 - acc: 0.7613\n",
      "Epoch 12: val_loss did not improve from 0.57561\n",
      "669/669 [==============================] - 50s 74ms/step - loss: 0.6095 - acc: 0.7613 - val_loss: 0.5925 - val_acc: 0.7738\n",
      "Epoch 13/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6097 - acc: 0.7591\n",
      "Epoch 13: val_loss improved from 0.57561 to 0.57304, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 51s 76ms/step - loss: 0.6097 - acc: 0.7591 - val_loss: 0.5730 - val_acc: 0.7794\n",
      "Epoch 14/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6056 - acc: 0.7566\n",
      "Epoch 14: val_loss improved from 0.57304 to 0.57032, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 52s 77ms/step - loss: 0.6056 - acc: 0.7566 - val_loss: 0.5703 - val_acc: 0.7783\n",
      "Epoch 15/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6026 - acc: 0.7623\n",
      "Epoch 15: val_loss improved from 0.57032 to 0.56739, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 55s 82ms/step - loss: 0.6026 - acc: 0.7623 - val_loss: 0.5674 - val_acc: 0.7855\n",
      "Epoch 16/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.6047 - acc: 0.7615\n",
      "Epoch 16: val_loss did not improve from 0.56739\n",
      "669/669 [==============================] - 50s 74ms/step - loss: 0.6047 - acc: 0.7615 - val_loss: 0.5913 - val_acc: 0.7815\n",
      "Epoch 17/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.5986 - acc: 0.7625\n",
      "Epoch 17: val_loss did not improve from 0.56739\n",
      "669/669 [==============================] - 52s 78ms/step - loss: 0.5986 - acc: 0.7625 - val_loss: 0.5724 - val_acc: 0.7836\n",
      "Epoch 18/20\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.5999 - acc: 0.7620\n",
      "Epoch 18: val_loss did not improve from 0.56739\n",
      "669/669 [==============================] - 51s 76ms/step - loss: 0.5999 - acc: 0.7620 - val_loss: 0.5717 - val_acc: 0.7860\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=epochs,\n",
    "    workers=-1, callbacks=callbacks_list,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T15:14:27.169841Z",
     "iopub.status.busy": "2023-10-09T15:14:27.169511Z",
     "iopub.status.idle": "2023-10-09T15:14:27.235060Z",
     "shell.execute_reply": "2023-10-09T15:14:27.234180Z",
     "shell.execute_reply.started": "2023-10-09T15:14:27.169814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " attention_masks (InputLayer)   [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n",
      "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
      "                                n_state=(None, None                                               \n",
      "                                , 768),                                                           \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 5)            3845        ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,486,085\n",
      "Trainable params: 109,486,085\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the bert_model\n",
    "bert_model.trainable = True\n",
    "# Recompile and fit again with smaller learning rate for fine-tuning\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(3e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T15:14:42.628497Z",
     "iopub.status.busy": "2023-10-09T15:14:42.628135Z",
     "iopub.status.idle": "2023-10-09T15:20:51.161756Z",
     "shell.execute_reply": "2023-10-09T15:20:51.160906Z",
     "shell.execute_reply.started": "2023-10-09T15:14:42.628468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.8325\n",
      "Epoch 1: val_loss improved from 0.56739 to 0.35719, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 163s 178ms/step - loss: 0.4505 - accuracy: 0.8325 - val_loss: 0.3572 - val_accuracy: 0.8790\n",
      "Epoch 2/3\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.2399 - accuracy: 0.9154\n",
      "Epoch 2: val_loss improved from 0.35719 to 0.33621, saving model to circa_qa_bert_trial.h5\n",
      "669/669 [==============================] - 104s 155ms/step - loss: 0.2399 - accuracy: 0.9154 - val_loss: 0.3362 - val_accuracy: 0.8898\n",
      "Epoch 3/3\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.9589\n",
      "Epoch 3: val_loss did not improve from 0.33621\n",
      "669/669 [==============================] - 102s 152ms/step - loss: 0.1236 - accuracy: 0.9589 - val_loss: 0.4439 - val_accuracy: 0.8904\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=3,\n",
    "    workers=-1,verbose=1,callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T15:21:07.746323Z",
     "iopub.status.busy": "2023-10-09T15:21:07.745984Z",
     "iopub.status.idle": "2023-10-09T15:21:20.290446Z",
     "shell.execute_reply": "2023-10-09T15:21:20.289365Z",
     "shell.execute_reply.started": "2023-10-09T15:21:07.746297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 12s 64ms/step - loss: 0.4456 - accuracy: 0.8900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44557836651802063, 0.8899872303009033]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T15:58:31.097922Z",
     "iopub.status.busy": "2023-10-09T15:58:31.097603Z",
     "iopub.status.idle": "2023-10-09T15:58:31.102286Z",
     "shell.execute_reply": "2023-10-09T15:58:31.101103Z",
     "shell.execute_reply.started": "2023-10-09T15:58:31.097896Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_data_pred = BertSemanticDataGenerator(\n",
    "#     test[[\"question-X\", \"answer-Y\"]].values.astype(\"str\"),\n",
    "#     labels=None,\n",
    "#     batch_size=test.shape[0],\n",
    "#     include_targets=False,\n",
    "#     shuffle=False\n",
    "# )\n",
    "\n",
    "# predicted = model.predict([test_data_pred])\n",
    "# predicted.shape\n",
    "\n",
    "# predicted_vector = predicted.copy()\n",
    "\n",
    "# predicted_vector[predicted_vector > 0.5] = 1\n",
    "# predicted_vector[predicted_vector <= 0.5] = 0\n",
    "# predicted_vector\n",
    "\n",
    "\n",
    "# print(classification_report(y_test, predicted_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T15:37:14.380197Z",
     "iopub.status.busy": "2023-10-09T15:37:14.379858Z",
     "iopub.status.idle": "2023-10-09T15:37:14.390592Z",
     "shell.execute_reply": "2023-10-09T15:37:14.389633Z",
     "shell.execute_reply.started": "2023-10-09T15:37:14.380169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(goldstandard2\n",
       " Yes                                  15745\n",
       " No                                   11985\n",
       " Yes, subject to some conditions       2580\n",
       " In the middle, neither yes nor no      701\n",
       " Other                                  504\n",
       " Name: count, dtype: int64,\n",
       " label_2\n",
       " 0    15745\n",
       " 1    11985\n",
       " 2     2580\n",
       " 3      701\n",
       " 4      504\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['goldstandard2'].value_counts(), data['label_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T15:37:17.350453Z",
     "iopub.status.busy": "2023-10-09T15:37:17.350098Z",
     "iopub.status.idle": "2023-10-09T15:37:17.361418Z",
     "shell.execute_reply": "2023-10-09T15:37:17.360543Z",
     "shell.execute_reply.started": "2023-10-09T15:37:17.350424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4],\n",
       " ['Yes',\n",
       "  'No',\n",
       "  'Yes, subject to some conditions',\n",
       "  'In the middle, neither yes nor no',\n",
       "  'Other'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(set(data['label_2']))\n",
    "labels_text = list(data['goldstandard2'].value_counts().index)\n",
    "\n",
    "labels, labels_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T15:37:24.063426Z",
     "iopub.status.busy": "2023-10-09T15:37:24.063078Z",
     "iopub.status.idle": "2023-10-09T15:37:24.069108Z",
     "shell.execute_reply": "2023-10-09T15:37:24.068086Z",
     "shell.execute_reply.started": "2023-10-09T15:37:24.063388Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_indirect(question, answer):\n",
    "    sentence_pairs = np.array([[str(question), str(answer)]])\n",
    "    test_data = BertSemanticDataGenerator(\n",
    "        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
    "    )\n",
    "\n",
    "    proba = model.predict(test_data[0])[0]\n",
    "    print(proba)\n",
    "    idx = np.argmax(proba)\n",
    "    print(idx)\n",
    "    proba = f\"{proba[idx]: .2f}%\"\n",
    "    pred = labels_text[idx]\n",
    "    return pred, proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T15:37:39.908945Z",
     "iopub.status.busy": "2023-10-09T15:37:39.908614Z",
     "iopub.status.idle": "2023-10-09T15:37:42.685360Z",
     "shell.execute_reply": "2023-10-09T15:37:42.684391Z",
     "shell.execute_reply.started": "2023-10-09T15:37:39.908919Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "[9.99886632e-01 1.90073831e-06 7.91925231e-06 1.03301245e-04\n",
      " 2.42448152e-07]\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Yes', ' 1.00%')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Do you like Italian food?\"\n",
    "answer = \"I just had an awesome pasta yesterday for dinner!\"\n",
    "check_indirect(question, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completely unseen examples; BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T16:01:47.056022Z",
     "iopub.status.busy": "2023-10-09T16:01:47.055676Z",
     "iopub.status.idle": "2023-10-09T16:01:50.480131Z",
     "shell.execute_reply": "2023-10-09T16:01:50.479113Z",
     "shell.execute_reply.started": "2023-10-09T16:01:47.055995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "[9.9981278e-01 3.2126896e-05 1.4676831e-07 1.5190245e-04 3.0277970e-06]\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Yes', ' 1.00%')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Did you eat the last piece of cake?\"\n",
    "answer = \"I really enjoyed it. It was delicious!\"\n",
    "check_indirect(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T16:02:48.902482Z",
     "iopub.status.busy": "2023-10-09T16:02:48.902115Z",
     "iopub.status.idle": "2023-10-09T16:02:49.112342Z",
     "shell.execute_reply": "2023-10-09T16:02:49.111455Z",
     "shell.execute_reply.started": "2023-10-09T16:02:48.902452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "[2.5426280e-02 8.5577679e-01 6.7016357e-03 1.1209398e-01 1.3051811e-06]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('No', ' 0.86%')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question =  \"Are you coming to the meeting tomorrow?\"\n",
    "answer = \"I'll need to check my schedule and see what's going on.\"\n",
    "check_indirect(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T16:03:36.723054Z",
     "iopub.status.busy": "2023-10-09T16:03:36.722723Z",
     "iopub.status.idle": "2023-10-09T16:03:36.927767Z",
     "shell.execute_reply": "2023-10-09T16:03:36.926753Z",
     "shell.execute_reply.started": "2023-10-09T16:03:36.723028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "[2.0725550e-03 9.9427915e-01 1.5510622e-06 3.6467698e-03 2.9226713e-08]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('No', ' 0.99%')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question =  \"Did you finish the report I asked you to complete?\"\n",
    "answer = \"I worked on it for a while, but I got busy with other things.\"\n",
    "check_indirect(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T16:06:06.102409Z",
     "iopub.status.busy": "2023-10-09T16:06:06.102030Z",
     "iopub.status.idle": "2023-10-09T16:06:06.402993Z",
     "shell.execute_reply": "2023-10-09T16:06:06.401936Z",
     "shell.execute_reply.started": "2023-10-09T16:06:06.102357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "[4.5017678e-05 9.9720675e-01 1.7755976e-05 2.7304005e-03 4.9983829e-08]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('No', ' 1.00%')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question =   \"Have you decided on your vacation destination?\"\n",
    "answer = \"I'm thinking about a few places, but I need to check my budget first.\"\n",
    "check_indirect(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T16:07:08.154056Z",
     "iopub.status.busy": "2023-10-09T16:07:08.153724Z",
     "iopub.status.idle": "2023-10-09T16:07:08.364775Z",
     "shell.execute_reply": "2023-10-09T16:07:08.363721Z",
     "shell.execute_reply.started": "2023-10-09T16:07:08.154031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "[7.3138118e-04 9.7705680e-01 4.2767674e-04 2.1784218e-02 5.7693395e-08]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('No', ' 0.98%')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Did you enjoy the service that we provided?\"\n",
    "answer = \"I would have to say yes to disappointment I'm afraid.\"\n",
    "check_indirect(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T16:10:18.054104Z",
     "iopub.status.busy": "2023-10-09T16:10:18.053755Z",
     "iopub.status.idle": "2023-10-09T16:10:18.269944Z",
     "shell.execute_reply": "2023-10-09T16:10:18.268961Z",
     "shell.execute_reply.started": "2023-10-09T16:10:18.054077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "[7.0891581e-03 1.1050723e-01 4.0677926e-03 8.7833494e-01 8.5300246e-07]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('In the middle, neither yes nor no', ' 0.88%')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Did you like the book you just finished?\"\n",
    "answer = \"The ending was unexpected, but I had mixed feelings about the characters.\"\n",
    "check_indirect(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T16:12:55.591267Z",
     "iopub.status.busy": "2023-10-09T16:12:55.590887Z",
     "iopub.status.idle": "2023-10-09T16:12:55.805218Z",
     "shell.execute_reply": "2023-10-09T16:12:55.803902Z",
     "shell.execute_reply.started": "2023-10-09T16:12:55.591238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "[2.2333125e-02 4.9651385e-06 9.7673029e-01 9.3160651e-04 1.3586288e-08]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Yes, subject to some conditions', ' 0.98%')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Are you willing to contribute to the charity?\"\n",
    "answer = \"I'm open to it, provided it's a cause I believe in.\"\n",
    "check_indirect(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T16:14:00.707590Z",
     "iopub.status.busy": "2023-10-09T16:14:00.707231Z",
     "iopub.status.idle": "2023-10-09T16:14:00.916514Z",
     "shell.execute_reply": "2023-10-09T16:14:00.915449Z",
     "shell.execute_reply.started": "2023-10-09T16:14:00.707563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "[9.9999332e-01 1.8697001e-06 2.2875035e-06 2.4247577e-06 1.4637591e-10]\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Yes', ' 1.00%')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Want to go to the waterpark this weekend?\"\n",
    "answer = \"Let's get soaked!\"\n",
    "check_indirect(question, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-09T16:14:25.244456Z",
     "iopub.status.busy": "2023-10-09T16:14:25.244081Z",
     "iopub.status.idle": "2023-10-09T16:14:25.449664Z",
     "shell.execute_reply": "2023-10-09T16:14:25.448588Z",
     "shell.execute_reply.started": "2023-10-09T16:14:25.244427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "[6.6272798e-05 2.2034863e-02 4.8152498e-07 9.7789842e-01 1.1180090e-09]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('In the middle, neither yes nor no', ' 0.98%')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Will you support the new policy?\"\n",
    "answer = \"Haven't made up my mind yet.\"\n",
    "check_indirect(question, answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
